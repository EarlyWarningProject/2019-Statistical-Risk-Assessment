---
title: "Updating Data to be used in SRA"
author: "Julia Levine"
date: "June 19, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table)
library(readxl)
```

#Load in old data

The following code reads in the old data. It then takes the most recent data for each country and replicates it for the years that we are updating. There are two dataframes created: dat_old which has all of the data up to the most recent year (2017), and dat_new which is simply the 2017 data that will be updated for 2018. 

```{r}
load("prepared2017predictors_8_22_19.RData")

update_years <- c(2018)
carry_from <- max(dat$year)

# carries forward all data from the most recent year
dat_new <- do.call("rbind", (replicate(length(update_years), 
                                       dat[dat$year == carry_from, ], 
                                       simplify = FALSE)))
dat_new$year <- rep(update_years, each = nrow(dat_new))

# rename old data and leave it alone until you've updated all 
# variables except for the lag/leads
dat_old <- dat
rm(dat)

```

This chunk updates country age by adding the difference between the updated years and the year the data was carried from to the country age variable. 

```{r}
# update country age
diff <- update_years - carry_from

for(i in 1:length(update_years)){
  dat_new$countryage[dat_new$year == update_years[i]] <- 
  dat_new$countryage[dat_new$year == update_years[i]] + diff[i]
}

dat_new$countryage.ln <- log(dat_new$countryage + 1)
```



#Update dat_new

The following is a function that removes the variables that were carried forward from dat_old, and then merges in the updated variables from the appropriate year. As inputs, it takes "new_data", which is a dataframe containing updated variables for each country in the update years, and vectors listing the country and year variables in dat_new and the data to be merged onto it.

```{r}
merge_dat <- function(new_data, merge_new_by = c("sftgcode", "year"), 
                      merge_old_by = c("sftgcode", "year")){
  new_data_vars <- colnames(new_data)[!colnames(new_data) %in% merge_new_by]
  dat_new <- dat_new[, !(colnames(dat_new) %in% new_data_vars)]
  dat_new <- merge(dat_new, new_data, by.x = merge_old_by, 
             by.y = merge_new_by, all.x = TRUE)
  dat_new
}
```

##VDEM

The following code reads in the most recent V-DEM data, selecting only the update years for the relevant variables. 

```{r, eval = FALSE}
vdem <- fread("data/2019/vdem/V-Dem-CY-Full+Others-v9.csv")

# subset to just use these variables
vdem_vars <- c("v2cldmovem_ord", 
               "v2cldmovew_ord", 
               "v2clkill_ord",
               "v2clsocgrp_ord", 
               "v2clrgunev_ord", 
               "v2csreprss_ord",
               "v2pepwrsoc_ord", 
               "v2elrstrct", 
               "v2psparban_ord",
               "v2psoppaut_ord", 
               "v2jureform_ord", 
               "v2clrelig_ord",
               "v2xcl_disc", 
               "v2pepwrses_ord", 
               "v2pepwrses", 
               "e_migdpgro",
               "e_mipopula", 
               "e_cow_exports", 
               "e_cow_imports", 
               "e_migdppc"
               )
keep <- c("COWcode", "country_name", "year", vdem_vars)


# function that renames and formats variables, 
# takes dataset and vector of variables to keep as inputs
source("helper scripts/format_vdem.R")
# function that maps COW codes onto PITF country codes, 
# contained in format_vdem
source("helper scripts/cowtopitf2018.R")


vdem <- format_vdem(dat = vdem, keep = keep)
# save(vdem, file = "data/2019/vdem_keep.Rdata")
save(vdem, file = "data/2019/vdem_keep_8_22.Rdata")

```


This chunk removes the old year's V-DEM variables, and merges in the new ones.

```{r}
load("data/2019/vdem_keep_8_22.Rdata")
# load("data/2019/vdem_keep.Rdata")
vdem <- vdem[vdem$year %in% update_years, ]
# this ensures that we dont replace old country names, as VDEM sometimes changes them
vdem$country_name <- NULL
# update V-DEM data
dat_new <- merge_dat(new_data = vdem)
```





##Polity 

<!-- For now, we carry forward the polity2 variable, so there is no new data to merge. The durable variable is updated by adding the difference between the update years and the year the data was carried forward from to the durable variable.  -->

<!-- ```{r} -->
<!-- # update country age -->
<!-- diff <- update_years - carry_from -->

<!-- for(i in 1:length(update_years)){ -->
<!--   dat_new$durable[dat_new$year == update_years[i]] <-  -->
<!--   dat_new$durable[dat_new$year == update_years[i]] + diff[i] -->

<!--   dat_new$pol.durable[dat_new$year == update_years[i]] <-  -->
<!--   dat_new$pol.durable[dat_new$year == update_years[i]] + diff[i] -->
<!-- } -->

<!-- dat_new$pol.durable.ln <- log(dat_new$pol.durable + 1) -->
<!-- dat_new$durable.ln <- dat_new$pol.durable.ln # for no good reason,  -->
<!-- # we have this with a different name. -->
<!-- ``` -->

Changed on 9/19 in light of new data

```{r}
polity <- read_excel("data/2019/p4v2018.xls")
polity <- polity[polity$year %in% update_years, 
                 c("scode", "year", "polity2", "durable")]
```



```{r}
names(polity)[names(polity)=="scode"]="sftgcode"
polity$sftgcode[polity$sftgcode=="SER"] <- "SRB"
polity$sftgcode[polity$sftgcode=="MNT"] <- "MNE"
polity$sftgcode[polity$sftgcode=="GMY"] <- "GER"
polity$sftgcode[polity$sftgcode=="SSU"] <- "SSD"
polity$sftgcode[polity$sftgcode=="SDN"] <- "SUD"
polity$sftgcode[polity$sftgcode=="USR"] <- "USS"

# old <- dat_new[, c("sftgcode", "country_name", "polity2", "durable")]
dat_new <- merge_dat(new_data = polity)
# new <- dat_new[, c("sftgcode", "polity2", "durable")]

# compare <- merge(old, new, by = "sftgcode")

# na.omit(compare[compare$polity2.x != compare$polity2.y, ])
# 
# na.omit(compare[compare$durable.x != compare$durable.y - 1, ])
```

```{r}
dat_new$pol.durable <- dat_new$durable
dat_new$pol.durable.ln <- log(1 + dat_new$durable)
dat_new$durable.ln <- dat_new$pol.durable.ln
```


```{r}
# Fearon & Laitin regime type (autocracy, anocracy, democracy)
dat_new$polity2.fl=NA
dat_new$polity2.fl[!is.na(dat_new$polity2)]=0
dat_new$polity2.fl.1=dat_new$polity2.fl.2=dat_new$polity2.fl.3=dat_new$polity2.fl.7=dat_new$polity2.fl

dat_new$polity2.fl[dat_new$polity2 >= -10 & dat_new$polity2 < -5] <- 1  # Autocracy
dat_new$polity2.fl[dat_new$polity2 >= -5 & dat_new$polity2 <= 5] <- 2  # Anocracy
dat_new$polity2.fl[dat_new$polity2 > 5] <- 3  # Democracy
#dat_new$polity2.fl[dat_new$polity2 == -66 | dat_new$polity2 == -77 | dat_new$polity2 == -88 ] <- 7  # Other
# There are no -66, -77, -88 in polity2.

dat_new$polity2.fl.1[dat_new$polity2.fl==1]=1
dat_new$polity2.fl.2[dat_new$polity2.fl==2]=1
dat_new$polity2.fl.3[dat_new$polity2.fl==3]=1
#dat_new$polity2.fl.7[dat_new$polity2.fl==7]=1

dat_new$polity2_sq = dat_new$polity2^2
```

Shifts from last year: 

- armenia, bhutan, malaysia, honduras: anocracy to  democracy
- bangladesh goes from anocracy to autocracy
- comoros: democracy to anocracy
- cuba: anocracy to autocracy



##WDI

First, I pull the latest data from the API. This sometimes takes a while so skip to where I read in the formatted data, 3 chunks down.

```{r, eval = FALSE}
library(WDI)

# WDIsearch(string = "gdp")
wdilist <- c("NE.TRD.GNFS.ZS",     # Trade (% of GDP)
             "NY.GDP.PCAP.PP.KD",  # GDP per capita, PPP (constant 2005 intl $)
             "NY.GDP.PCAP.KD",     # GDP per capita (constant 2000 US$)
             "NY.GDP.MKTP.KD.ZG",  # GDP growth (annual %)
             "FP.CPI.TOTL.ZG",     # Inflation, consumer prices (annual %)
             "SP.POP.TOTL",        # Population, total
             "SP.DYN.IMRT.IN"     # Infant mortality rate
    )

# Extract latest version of desired variables from WDI 
wdi <- WDI(country="all", indicator=wdilist, extra=FALSE, start=min(update_years))

# check that you only pulled the years to be appended
wdi$year %>% table
```


```{r, eval = FALSE}
# Add PITF country codes for merging 
source("helper scripts/f.pitfcodeit.R")
wdi <- pitfcodeit(wdi, "country")


# In summer 2018, name of Swaziland was updated to eSwatini
wdi$country <- as.character(wdi$country)
wdi$country[wdi$country=="Eswatini"] <- "Swaziland"
wdi$sftgcode[wdi$country=="Swaziland"]="SWA"
```

```{r, eval = FALSE}
# Subset to drop cases with missing PITF codes, cut extra id vars
wdi <- subset(wdi, !is.na(sftgcode), select=-c(1, 2))


# Rename variables-- add a "new" to indicate these are newly brought in from wdi 
# to avoid reusing names already in the old EWP data
names(wdi) <- c("year",
                "wdi.trade.new",
                "wdi.gdppcppp.new",
                "wdi.gdppc.new",
                "wdi.gdppcgrow.new",
                "wdi.inflation.new",
                "wdi.popsize.new", 
                "wdi.imrate.new", 
                "sftgcode"
                )

# Reorder for easier review
wdi <- wdi[order(wdi$sftgcode, wdi$year),]

# check which variables are missing values
(missing <- apply(wdi, 2, function(x) sum(is.na(x))))

# check which variables are missing for all countries, indicating that they
# have not been updated yet, but potentially will be in the future
missing[missing == length(unique(wdi$sftgcode))]

write.csv(wdi, "data/2019/wdi_9_19", row.names = FALSE)
# write.csv(wdi, "data/2019/wdi_7_1", row.names = FALSE)
```



This chunk reads in the data pulled and formatted on 7/1/19. It merges this data into dat_new, with the exception of infant mortality rate, which is missing for 2018. We had previously been using this variable from V-DEM, but it is no longer being updated, so for 2016 and 2017 we carried it forward from 2015. WDI has now updated it for 2016 and 2017, but not 2018. For now, continue to use 2015 values. 

```{r, eval = FALSE}
wdi <- read.csv("data/2019/wdi_7_1")
wdi2 <- read.csv("data/2019/wdi_9_19")
all.equal(wdi, wdi2)

(missing1 <- apply(wdi, 2, function(x) sum(is.na(x))))
(missing2 <- apply(wdi2, 2, function(x) sum(is.na(x))))
```


```{r}
# wdi <- read.csv("data/2019/wdi_7_1")
wdi <- read.csv("data/2019/wdi_9_19")
# Merge it in:

dat_new <- merge_dat(new_data = wdi)

dat_new$wdi.imrate <- dat_new$wdi.imrate.new
# colnames(dat_new)
```


##UCDP battle-related deaths 

The following code reads in the UCDP data and changes country names to match. 

```{r}
ucdp = read_excel("data/2019/ucdp-brd-dyadic-191.xlsx")

# making sure we have the same variables as in 18.1 version. 
# colnames for 18.1 are uppercase, use tolower when checking
colnames(ucdp) <- gsub("_", "", colnames(ucdp))
# Side A ID not available in 18.1 version, delete it here
ucdp$sideaid <- NULL

ucdp = ucdp %>% filter(year %in% update_years & typeofconflict >= 3)

setdiff(unique(ucdp$locationinc), unique(dat_new$country_name))

ucdp$locationinc = as.character(ucdp$locationinc)

# changes from 18.1
ucdp$locationinc[ucdp$locationinc=="Myanmar (Burma)"] = "Burma/Myanmar"
ucdp$locationinc[ucdp$locationinc=="Yemen (North Yemen)"] = "Yemen"
ucdp$locationinc[ucdp$locationinc=="DR Congo (Zaire)"] = "Democratic Republic of Congo"
ucdp$locationinc[ucdp$locationinc=="Russia (Soviet Union)"] = "Russia"
ucdp$locationinc[ucdp$locationinc=="Congo"] = "Republic of the Congo"
```

Below, I sum the number of battledeaths for each country in the update years, and merge this onto dat_new. 

```{r}
bd <- ucdp[, c("bdbest", "year", "locationinc")]

# group by year/country and sum battledeaths
bd <- bd %>% group_by(locationinc, year) %>% summarise(battledeaths = sum(bdbest))

# quick check
# all.equal(dat_new$battledeaths, 
# dat_old$battledeaths[dat_old$year == carry_from])

dat_new <- merge_dat(new_dat = bd, 
                     merge_new_by = c("locationinc", "year"), 
                     merge_old_by = c("country_name", "year"))

dat_new$battledeaths[is.na(dat_new$battledeaths)] <- 0
dat_new$battledeaths.ln=log(dat_new$battledeaths+1)

# quick check
# all.equal(dat_new$battledeaths, 
# dat_old$battledeaths[dat_old$year == carry_from])
```


##Add new onsets

For all mass killing variables (grouped by state-led, non-state-led, or either), I carry forward values for if there was ever a mass killing, or if there is an ongoing mass killing. I will then changes values for specific countries if there is an onset in a country that never had one before, or if an event ended. The indicator variables for the start and end of a mass killing are initialized to 0, and updated if relevant. 

###State-led mass killings

```{r}
# initialize
dat_new$mkl.end <- 0
dat_new$mkl.start <- 0
dat_new$mkl.start.1 <- 0

# if there are new onsets, update start.1 for old data
```

Here I change the ongoing mass killing status of Sudan to 0 in years after 2016, and update mkl.end in 2016 to 1 for Sudan. 

```{r}
# there is still a mass killing ongoing, only one ended but the Darfur event is ongoing
# dat_new$mkl.ongoing[dat_new$sftgcode == "SUD"] <- 0

# only update is the Sudan event (ended in June 2016)
dat_old$mkl.end[dat_old$sftgcode == "SUD" & dat_old$year == 2016] <- 1
# dat_old$mkl.ongoing[dat_old$sftgcode == "SUD" & dat_old$year > 2016] <- 0


# check
old_ongoing <- dat_old$sftgcode[dat_old$mkl.ongoing == 1 & dat_old$year == 2016]
new_ongoing <- dat_new$sftgcode[dat_new$mkl.ongoing == 1]

# setdiff(new_ongoing, old_ongoing)
setdiff(old_ongoing, new_ongoing)
```

###Non-state led onsets

```{r}
# initialize
dat_new$nonstatemk.end <- 0
dat_new$nonstatemk.start <- 0
dat_new$nonstatemk.start.1 <- 0

# if there are new onsets, update start.1 for old data
```

There are no new non-state led onsets. 

###Combined onset variable

```{r}
# initialize
dat_new$anymk.start <- 0
dat_new$anymk.start.1 <- 0
dat_new$anymk.ongoing <- 0
dat_new$anymk.ever <- 0

```

```{r}
dat_new$anymk.start[dat_new$mkl.start==1|dat_new$nonstatemk.start==1]=1

# table(dat_new$mkl.start)
# table(dat_new$anymk.start)


dat_new$anymk.start.1[dat_new$mkl.start.1==1|dat_new$nonstatemk.start.1==1]=1

# table(dat_new$mkl.start.1)
# table(dat_new$anymk.start.1)

dat_new$anymk.ongoing[dat_new$mkl.ongoing==1|dat_new$nonstatemk.ongoing]=1

# table(dat_new$mkl.ongoing)
# table(dat_new$anymk.ongoing) adds 6

dat_new$anymk.ever[dat_new$mkl.ever==1|dat_new$nonstatemk.ever==1]=1

# table(dat_new$mkl.ever)
# table(dat_new$anymk.ever) adds 2 

```

###Coup Attempts

This code reads in the most updated version of the Powell and Thyne data which is posted on their website. It selects coups in the years to be updated

```{r, eval = FALSE}
coup_dat <- read.delim("http://www.uky.edu/~clthyn2/coup_data/powell_thyne_coups_final.txt")
new_coup <- coup_dat[coup_dat$year %in% update_years, ]
new_coup$coup <- factor(new_coup$coup)
write.csv(new_coup, "data/2019/new_coup_18", row.names = FALSE)
```

This updates the coup variables in dat_new.

```{r}
new_coup <- read.csv("data/2019/new_coup_18")
# set to 0 for years to be updated
dat_new$cou.s.d=0
dat_new$cou.f.d=0

if(nrow(new_coup)>0){
  for(i in 1:nrow(new_coup)){
  if(new_coup$coup[i] == 2){#successful coup
    dat_new$cou.s.d[dat_new$year == new_coup$year[i] & 
                   as.character(dat_new$country_name) == 
                     as.character(new_coup$country[i])] = 1
    dat_new$cou.f.d[dat_new$year == new_coup$year[i] & 
                   as.character(dat_new$country_name) == 
                     as.character(new_coup$country[i])] = 0
  }
  if(new_coup$coup[i] == 1){#failed coup
     dat_new$cou.s.d[dat_new$year == new_coup$year[i] & 
                    as.character(dat_new$country_name) == 
                      as.character(new_coup$country[i])] = 0
     dat_new$cou.f.d[dat_new$year == new_coup$year[i] & 
                    as.character(dat_new$country_name) == 
                      as.character(new_coup$country[i])] = 1
  }
}
}

dat_new$cou.any = ifelse(dat_new$cou.s.d>0 | dat_new$cou.f.d>0, 1, 0)
dat_new$coup.try.5yr <- 0
```




#Append new data

This appends dat_new to dat_old, creating the full data-set

```{r}
# check to make sure you can append the new data (variables are in the right order)
setdiff(colnames(dat_old), colnames(dat_new))
all.equal(colnames(dat_old), colnames(dat_new))
# reorder variables
dat_new <- dat_new[, colnames(dat_old)]
# check again
all.equal(colnames(dat_old), colnames(dat_new))
# append new data
dat <- rbind(dat_old, dat_new)
```




#Leads and Lags

In this section, I update the variables that involve leads and lags




```{r}

# load("prepared2018predictors.RData")

cou_countries <- unique(na.omit(dat$sftgcode[dat$cou.any == 1]))

for(i in 1:length(cou_countries)){
  ind <- na.omit(dat$year[dat$sftgcode == cou_countries[i] & dat$cou.any == 1])
  end <- ind + 4
  seq <- as.vector(sapply(1:length(ind), function(x) ind[x]:end[x]) )
  seq <- unique(seq)
  dat$coup.try.5yr[dat$sftgcode == cou_countries[i] & dat$year %in% seq] <- 1
}
```


```{r}
dat$anymk.start.1[dat$year == 2017] <- 0

```

```{r}
mk_lookup <- dat[dat$anymk.start.1 == 1, c("year", "sftgcode", "anymk.start.1")]
mk_lookup$start.2 <- mk_lookup$year - 1
mk_lookup$start.3 <- mk_lookup$year - 2
mk_lookup$anymk.start.2 <- 1
mk_lookup$anymk.start.3 <- 1
# dat2$anymk.start.2 %>% is.na %>% sum
# dat2$anymk.start.2 %>% table

dat$anymk.start.2 <- NULL
dat$anymk.start.3 <- NULL
dat$last_year <- NULL

dat <- merge(dat, mk_lookup[, c("anymk.start.2", "sftgcode", "start.2")], 
             by.x = c("year", "sftgcode"), by.y = c("start.2", "sftgcode"), 
             all.x = TRUE)

dat <- merge(dat, mk_lookup[, c("anymk.start.3", "sftgcode", "start.3")], 
             by.x = c("year", "sftgcode"), by.y = c("start.3", "sftgcode"), 
             all.x = TRUE)

dat$anymk.start.2[is.na(dat$anymk.start.2)] <- 0
dat$anymk.start.3[is.na(dat$anymk.start.3)] <- 0

```

```{r}
uniquecountries <- unique(dat$sftgcode)
last_year <- sapply(uniquecountries, function(x) max(dat$year[dat$sftgcode == x]))
max_year <- data.frame(uniquecountries, last_year)

dat <- merge(dat, max_year, by.x = "sftgcode", 
             by.y = "uniquecountries", all.x = TRUE)


# last_year is a variable documenting the last year an sftgcode was used. we have no data past that so we can only have a 1 year lead for years <= (last_year - 1)
dat$anymk.start.1[dat$year>dat$last_year - 1] = NA
dat$anymk.start.2[dat$year>dat$last_year - 2] = NA
dat$anymk.start.3[dat$year>dat$last_year - 3] = NA


dat = dat %>% mutate(anymk.start.2window = as.numeric(anymk.start.1 | anymk.start.2),
                     anymk.start.3window = as.numeric(anymk.start.1 | anymk.start.2 | anymk.start.3))

# table(dat$anymk.start.2, dat$year)
# table(dat$anymk.start.3, dat$year)

# Make these windows also NA where there is not enough time left
# to code the whole window
dat$anymk.start.2window[dat$year>(dat$last_year - 2)] = NA
dat$anymk.start.3window[dat$year>(dat$last_year - 3)] = NA


dat=as.data.frame(dat)
```

```{r}
dat$year[dat$anymk.start.1 == 1|dat$anymk.start.1 == 0] %>% na.omit %>% max
dat$year[dat$anymk.start.2 == 1|dat$anymk.start.2 == 0] %>% na.omit %>% max
dat$year[dat$anymk.start.3 == 1|dat$anymk.start.3 == 0] %>% na.omit %>% max
```

#Data Preparation

```{r}
# index for which rows are to be updated, so we don't mess with previous info
ind <- which(dat$year %in% update_years)
```

only run if there are updates to WDI infant mortality rates

```{r}
# only run if there are updates to WDI infant mortality rates
# dat$imr.sqrt %>% summary
# dat$wdi.imrate[dat$year %in% update_years] %>% summary

# sum(is.na(dat$wdi.imrate[dat$year == 2018]))
dat$imr.sqrt[ind] = sqrt(dat$wdi.imrate)[ind]
```

##Remake some variables

This section fills in some V-DEM variables by creating an adjusted version of the relevant WDI variable. This significantly cuts down on missingness.

###Tradeshare

```{r}
dat$tradeshare.ln[ind]=log(dat$tradeshare)[ind]  
dat$wdi.trade.ln.new[ind] = log(dat$wdi.trade.new[ind])

# Make an adjusted version of the wdi one to fit the tradeshare (VDEM) one:
lm.adjust.trade = lm(tradeshare.ln~wdi.trade.ln.new, data=dat)

dat$wdi.trade.ln.new.adj[ind]=lm.adjust.trade$coefficients[1] + lm.adjust.trade$coefficients[2]*dat$wdi.trade.ln.new[ind]

#Where tradeshare is missing, replace with the adjusted wdi.trade.ln.new
dat$tradeshare.ln.combined[ind] = dat$tradeshare.ln[ind]
dat$tradeshare.ln.combined[dat$year %in% update_years & 
                             is.na(dat$tradeshare.ln)] <- 
  dat$wdi.trade.ln.new.adj[dat$year %in% update_years & 
                             is.na(dat$tradeshare.ln)]

sum(is.na(dat$tradeshare.ln[dat$year %in% update_years]))
sum(is.na(dat$tradeshare.ln.combined[dat$year %in% update_years])) 
#Cuts missingness a good bit
```

###Population size
```{r}
# Similarly, popsize is missing from both VDEM and WDI.

# Make and adjusted version of the wdi one to fit the tradeshare (VDEM) one:
lm.adjust.popsize = lm(popsize~wdi.popsize.new, data=dat)
dat$wdi.popsize.new.adj[ind]=lm.adjust.popsize$coefficients[1] + lm.adjust.popsize$coefficients[2]*dat$wdi.popsize.new[ind]

#Where popsize is missing, replace with the adjusted wdi.trade.ln.new
dat$popsize.combined[ind] = dat$popsize[ind]
dat$popsize.combined[dat$year %in% update_years & 
                       is.na(dat$popsize)] <- 
  dat$wdi.popsize.new.adj[dat$year %in% update_years & 
                            is.na(dat$popsize)]

sum(is.na(dat$popsize[dat$year %in% update_years]))
sum(is.na(dat$popsize.combined[dat$year %in% update_years])) 

dat$popsize.ln.combined[ind] = log(dat$popsize.combined)[ind]
```


```{r}
# First, we are only looking at countries over .5 million in pop
# (Changed from 1 million, 25 May 2018)

dat$country_name[is.na(dat$popsize.combined) & dat$year %in% update_years]
### We need population data for Eritrea, North Korea

### For now, let those with population = NA thgrough. 
dat = filter(dat, popsize.combined>.5e6 | is.na(popsize.combined))
```

###GDP per capita growth

```{r}
# The gdp growth figures from VDEM and WDI aren't as correlated as you'd like, but
# again WDI is missing before 1960 while the VDEM ones typically stop early.
with(dat, cor(wdi.gdppcgrow.new, gdppcgrowth, use="complete.obs"))
# Make and adjusted version of the wdi one to fit the tradeshare (VDEM) one:
lm.adjust.gdppcgrowth = lm(gdppcgrowth~wdi.gdppcgrow.new, data=dat)
dat$wdi.gdppcgrow.new.adj[ind]=lm.adjust.gdppcgrowth$coefficients[1] + 
  lm.adjust.gdppcgrowth$coefficients[2]*dat$wdi.gdppcgrow.new[ind]

#Where gdp missing from vdem, replace with WDI.
dat$gdppcgrowth.combined[ind] = dat$gdppcgrowth[ind]
dat$gdppcgrowth.combined[dat$year %in% update_years & 
                           is.na(dat$gdppcgrowth)] <- 
  dat$wdi.gdppcgrow.new.adj[dat$year %in% update_years & 
                              is.na(dat$gdppcgrowth)]

sum(is.na(dat$gdppcgrowth[dat$year %in% update_years]))
sum(is.na(dat$gdppcgrowth.combined[dat$year %in% update_years])) 
```








#Missingness

This section looks at remaining missingness and attempts to fill in values. 

```{r}

predictornames <- c("anymk.ongoing","anymk.ever",
                    "reg.afr", "reg.eap", "reg.eur", "reg.mna", "reg.sca", 
                    "countryage.ln", "popsize.ln.combined", "imr.sqrt",
                    "gdppcgrowth.combined",
                    "ios.iccpr1","includesnonstate",
                    "durable.ln","minorityrule", "elf.ethnic", "battledeaths.ln",
                    "candidaterestriction", "partyban","judicialreform",
                    "religiousfreedom", "pol_killing_approved",
                    "freemove_men4","freemove_women4", "freediscussion",
                    "social_inequality","even_civilrights","repress_civilsoc", 
                    "social_power_dist", "ses_power_dist",
                    "tradeshare.ln.combined", 
                    "coup.try.5yr",
                    "polity2.fl.2","polity2.fl.3")

```

```{r}

dat.check = dat[dat$year %in% update_years, 
                c("country_name","year", predictornames)]

comp <- lapply(update_years, 
               function(y) apply(dat.check[dat.check$year == y,], 
                                 2, function(x) sum(is.na(x))))
na.count <- unlist(comp)
years <- rep(update_years, each = ncol(dat.check))
check <- data.frame(na.count, years, names(na.count))

check <- check[check$na.count > 0 & !(check$names.na.count. %in% 
                                        c("anymk.start.1", "mkl.start.1")), ]

missing1 <- ggplot(check) + 
  geom_bar(aes(y = na.count, x = names.na.count., fill = factor(years)), 
           stat = "identity")+ 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  labs(x = "Missing Variables", y = "Number of Observations Missing", 
       fill = "Year", title = "Number of Countries with Missing Values Before Fixing")

missing1
# Tradeshare.ln.combined is still the biggest trouble maker.
```



##Fix missingness



```{r}
# function to look at patterns in NAs over time for each country with missing values
library(purrr)
look_na <- function(variable){
  missing <- dat[is.na(dat[, variable]) & dat$year %in% update_years, c("year", "country_name")]
  countries <- unique(missing$country_name)
  look <-lapply(1:length(countries), function(x) dat[dat$country_name == countries[x], c("year", variable)])
  
  look <- reduce(look,full_join, by = "year")
  colnames(look) <- c("year", as.character(countries))
  look <- look[order(look$year, decreasing = TRUE), ]
  look
}
```


```{r}
# function to carry forward values of a variable


carry_forward <- function(variable, year){
  na_var <- dat$sftgcode[is.na(dat[, variable]) & dat$year == year]
  carry_var <- dat_old[dat_old$year == carry_from & 
                         dat_old$sftgcode %in% na_var,
                       c(variable, "sftgcode")]
  for(i in 1:length(na_var)){
  dat[dat$sftgcode == carry_var$sftgcode[i] & dat$year == year, variable] <- 
    carry_var[i, variable]
  }
  dat
}

```


###gdp pc growth combined

```{r}
look_gdppcgrowth <- look_na("gdppcgrowth.combined")
head(look_gdppcgrowth)

# number of countries for which this variable is missing
ncol(look_gdppcgrowth) - 1
```

```{r, echo = FALSE}
#Cuba

#Eritrea

#Iran

#Somalia

#South Sudan

#Syria

#Venezuela

```

###imr.sqrt

This is only missing for Taiwan, which is missing most other variables.

```{r}
look_imr <- look_na("imr.sqrt")
head(look_imr)

```


###popsize.ln.combined

```{r}
look_popsize <- look_na("popsize.ln.combined")
head(look_popsize)

# Eritrea
# population, from CIA factbook, for estimate from July 2018
dat[dat$country_name=="Eritrea" & (dat$year==2018), "popsize.combined"] = 5970646
dat[dat$country_name=="Eritrea" & (dat$year==2018), "popsize.ln.combined"] = log(5970646)

# number of countries for which this variable is missing
ncol(look_popsize) - 1
```


###tradeshare.ln.combined

```{r}
look_tradeshare <- look_na("tradeshare.ln.combined")
head(look_tradeshare)

# number of countries for which this variable is missing
ncol(look_tradeshare) - 1
```

```{r, echo = FALSE}
# colnames(look_tradeshare)

# "Afghanistan"              
# "Algeria"                 
# "Angola"                   
# "Bhutan"                   
# "Burma/Myanmar"           
# "Burundi"                  
# "Central African Republic" 
# "Comoros"                 
# "Cuba"                     
# "Eritrea"                  
# "Fiji"                    
# "Gabon"                    
# "Ghana"                    
# "Guyana"                  
# "Iran"                     
# "Israel"                   
# "Jamaica"                 
# "Japan"                    
# "Kazakhstan"               
# "Kuwait"                  
# "Laos"                     
# "Lesotho"                  
# "Madagascar"              
# "Malawi"                   
# "New Zealand"              
# "Niger"                   
# "Nigeria"                  
# "Panama"                   
# "Papua New Guinea"        
# "Qatar"                    
# "Sierra Leone"             
# "Solomon Islands"         
# "South Sudan"              
# "Swaziland"                
# "Syria"
# "Tajikistan"               
# "Tanzania"                 
# "The Gambia"              
# "Timor-Leste"              
# "Trinidad and Tobago"      
# "Tunisia"                 
# "United States of America" 
# "Venezuela"                
# "Yemen"
```

###polity

```{r}
look_polity <- look_na("polity2.fl.2")
head(look_polity)

look_polity <- look_na("polity2.fl.3")
head(look_polity)
```


###Carry forward

Usually, missingness is filled in using the CIA Factbook. However, since it has not been updated for 2018, three variables are carried forward. 
```{r}
# CIA Factbook has not been updated for 2018. For now carry forward values 
dat <- carry_forward(variable = "popsize.ln.combined", year = 2018)
dat <- carry_forward("gdppcgrowth.combined", year = 2018)
dat <- carry_forward(variable = "tradeshare.ln.combined", year = 2018)
dat <- carry_forward(variable = "imr.sqrt", year = 2018)
dat <- carry_forward(variable = "polity2.fl.2", year = 2018)
dat <- carry_forward(variable = "polity2.fl.3", year = 2018)
```










```{r}
dat.check = dat[dat$year %in% update_years & dat$country_name != "Taiwan", 
                c("country_name","year", predictornames)]

comp <- lapply(update_years, function(y) apply(dat.check[dat.check$year == y,], 
                                               2, function(x) sum(is.na(x))))
na.count <- unlist(comp)
years <- rep(update_years, each = ncol(dat.check))
check <- data.frame(na.count, years, names(na.count))

check <- check[check$na.count > 0 & !(check$names.na.count. %in% 
                                        c("anymk.start.1", "mkl.start.1")), ]

missing2 <- ggplot(check) + 
  geom_bar(aes(y = na.count, x = names.na.count., fill = factor(years)), 
           stat = "identity")+ 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  labs(x = "Missing Variables", y = "Number of Observations Missing", 
       fill = "Year", title = "Number of Countries with Missing Values After Fixing")

missing2
```

This code just checks again that there are no missing values left. 

```{r}
dat.check = dat[dat$year %in% update_years & dat$country_name != "Taiwan", 
                c("country_name","year", predictornames)]

comp <- lapply(update_years, function(y) apply(dat.check[dat.check$year == y,], 
                                               2, function(x) sum(is.na(x))))
na.count <- unlist(comp)
years <- rep(update_years, each = ncol(dat.check))
check <- data.frame(na.count, years, names(na.count))
# there should be no variables still missing
check$names.na.count.[check$na.count>0]
```







```{r}
save(dat, file = "../Modelling/prepared2018predictors_9_19_19.RData")
save(dat, file = "prepared2018predictors_9_19_19.RData")
```

```{r}
load("prepared2018predictors_9_19_19.RData")
write.csv(dat, "prepared2018predictors.csv", row.names = FALSE)
```








